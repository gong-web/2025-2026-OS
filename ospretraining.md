## OS_Introduction

操作系统是什么？主板、cpu、内存、显示器等等拆解后。不用汇编语言写大规模是因为容易出错，通过编译链接会获得取址码。操作系统是连接**硬件资源**（主板、CPU、内存、显示器等）与**应用程序**之间的中介。生成一段指令来执行，硬编码了一系列的地址。内存不一样是如何知道的，在app下载的时候，内存条扩容了内存，在原来小内存上的跑的程序仍然可以跑。为什么不用关心内存大小的差异？

早期的计算机系统智能在这一个操作系统上执行，读进磁带，放到内存。早期程序员计算数据。取数据做运算。验证成熟的代码，不习惯替换他，崭新的东西没人知道是不是对的。操作系统参与到程序的运行过程之中，通过修改程序可以修改其内存地址。每个任务依次执行。排队依次执行。应用人员对计算机开发了程序。管理员可以进行调代码，手动地修改内存。也可以同时运行4个程序，所有的任务独立地并行执行。

为什么程序不需要关心内存大小？

- 操作系统屏蔽了内存大小的差异，提供了统一的抽象。
- 比如内存条升级后，原来的程序依旧可以运行，无需重写代码。

分时复用：每个任务只占了一个时间片，

![image-20250716093942864](C:\Users\gds\AppData\Roaming\Typora\typora-user-images\image-20250716093942864.png)

## 进程

是计算机一种宝贵的社会资源。如何尽可能地充分利用设备？排队、分时共享，得到一个编程手册。接受什么指令，完成什么运算，指令什么功能，将指令以批进入计算机之中。完成一个工作的时间变短，内存增加可以走更多的程序。切成小的片段，空闲的时间运行其他的程序。若干的程序有更多的时间片。时间片越小，服务的用户更多。

### 并行与并发

并行：两台计算机执行两个独立的任务；并发：一台计算机通过时间切片和快速切换使之看起来像在两个计算机上运行。并发有价值吗？我们的程序并不总是在适用cpu，会过一段时间与用户进行交互，运行时间，得到结果，调用设备等等。第一个程序在用cpu，第二个程序也可以发出，因为没有使用cpu。两个程序如果在同一个时刻争抢设备，并发是无效的。

| 概念     | 说明                                                   |
| -------- | ------------------------------------------------------ |
| **并行** | 多个任务同时在**多个处理器上执行**。                   |
| **并发** | 多个任务在**一个处理器上快速切换**执行，看似同时运行。 |

### 存档与读档

每一个运行的程序能够存档和读档。有没有开辟内存，内存中的值，寄存器中的值，装载到那个内存。cpu只有一个内存有四份。cpu可以分为alu寄存器和访存单元，需要存档寄存器，不用存alu，alu没有状态。程序的状态来自于内存变量，临时的状态来自于寄存器，寄存器和cpu密切联系在一起。根据指令的要求改变寄存器的数据。

操作系统通过进程实现程序的**存档与读档**功能：

- 存档：保存寄存器状态（ALU 无状态不需保存）。
- 读档：将状态加载回寄存器，恢复执行。

在寄存器不足，硬盘、网络都不合适，存在内存之中，把寄存器组写进去，这就是把程序的运行状态存档。正在运行的程序决定不运行，存在一个指定的内存之中。读取的存档寄存器的值加载在真正的寄存器上即可。程序不用cpu了，可以选择其他设备，判断就是通过是不是调用了函数，判断不用就是这个固定的函数返回值了。

<img src="C:\Users\gds\AppData\Roaming\Typora\typora-user-images\image-20250716103703668.png" alt="image-20250716103703668" style="zoom:50%;" />

### 程序与进程

面向对象的语言重写操作系统。进程：抽象的数据结构。

![image-20250716104123623](C:\Users\gds\AppData\Roaming\Typora\typora-user-images\image-20250716104123623.png)

帮程序存档读档以及接口函数，封装成类的基本函数，派生类对应到不同的应用程序上。继承出来的类可以创建对象，派生出新的类。.exe。需要创建一个窗口类的工具以及一个数据结构。分时复用cpu，若干个程序从若干个进程之中产生。程序是图标，双击得到进程，每一个进程有独立的数据，每一个程序有它里面相应的东西。进程是一段代码和他的数据在运行过程之中的状态。同一个时刻在系统之中只有一个进程在运行，一个进程死了再换下一个进程运行。现代化分时复用技术上有一个cpu和各自运行的程序。为了完成切换，我们定义了一系列的数据结构和接口函数，接口函数我们叫做进程。

**程序**：硬盘上的可执行文件（如 `.exe`），静态。

**进程**：程序运行起来之后的实例，动态。

- 每次双击图标，都会产生一个新的进程。
- 每个进程拥有独立的内存、指令指针、寄存器等状态信息。

现代化不只是一个cpu或不只是一个函数，多线程同时运动，每一个cpu负责渲染一个东西，多核多线程。记事本是一个可执行的程序放在文件夹之中，进程想要运行，要恢复成指令和数据填给cpu，可以加载若干次来给cpu。

如何运行进程，独立的指令区域和数据区域，还有都会用到的区域。

不再只有一个 CPU，而是支持**多核多线程**。

- 每个 CPU 核心可负责不同任务（如图形渲染、后台服务等）。

通过**进程调度算法**实现高效的进程切换。

程序运行时：

- 被加载为**指令区域**和**数据区域**。
- 操作系统负责将其分配到合适的内存地址空间，并执行。

创造出管理进程的数据结构：进程控制块（Process Control Block, PCB）是操作系统用于管理进程的核心数据结构。每个进程都有一个对应的PCB，用于存储该进程的所有关键信息，以支持进程的创建、调度、执行和终止。PCB是操作系统管理进程的基础。同样类型不知道多少个用链表来描述。存盘点（context），很多个上下文（PCB），串接若干个PCB，双链表浪费空间但移动效率高，单链表相反，哈希链表、跳表等等。“存档”即为上下文。一个进程放弃了运行，另一个进程也想运行。

**上下文**：进程的上下文是指进程在某一时刻的运行状态，主要包括：

- **程序计数器（PC）**：指向下一条要执行的指令地址。
- **寄存器状态**：包括通用寄存器、栈指针、状态寄存器等，用于保存进程的执行环境。

**存盘点**：存盘点是进程上下文的“快照”，用于保存进程暂停执行时的状态，以便后续恢复。存盘点记录了进程在暂停时下一条要执行的指令（PC值）以及相关寄存器的值。

当一个进程（例如P1）暂停执行时，操作系统会为该进程创建一个存盘点，将其上下文（包括PC和寄存器状态）保存到PCB中。随后，操作系统选择另一个进程（例如P0）的PCB，将其上下文从内存恢复到CPU的寄存器中，使其继续执行。

system idle所有进程不用cpu他来用。一个进程不想用cpu应该先存档，然后选一个运行。把选取到的PCB加载到cpu上。把PCB从内存回复到指令运行的时候，上下文即准备这条运行指令的寄存器，PC决定即将要取的那个状态的指令。PC是即将执行的下一条指令，PC存了下面寄存器的值以及PC，PCB从内存恢复到寄存器，是P1创造存盘点原本要执行的下一条指令。

<img src="C:\Users\gds\AppData\Roaming\Typora\typora-user-images\image-20250716112916803.png" alt="image-20250716112916803" style="zoom:33%;" />

蓝色是cpu的执行轨迹，执行到某一瞬间决定存盘以及此时应该执行哪个，p1不想执行时，为p1创建一个存盘点，把p0从存盘点之中恢复出来，关键是恢复pc。存盘点存储着他想要执行的下一条指令

<img src="C:\Users\gds\AppData\Roaming\Typora\typora-user-images\image-20250808095529259.png" alt="image-20250808095529259" style="zoom: 33%;" />

创建存盘点并告知下面要执行什么，存的是假设不存盘向后执行的东西，存什么值用什么填PC，为了切换后还能向后执行。

进程的上下文切换，最常见的是sleep，操作系统创建一个存盘点，在存盘点之后向后进行。三件事情：创建存盘点、上一个闹钟、闹钟到来的时候回复存盘点。是程序和操作系统自发的行为，pc存在sleep下面的一行。上下文控制只能用汇编来做，进程上下文切换的任务。进程当前的上下文在寄存器上，存下来是指把寄存器搬运到对应的内存；回复内存存档的上下文是指把内存中的值放到寄存器上。存一个进程的上下文，把p0状态存进去，读p1的状态，不同体系结构操作pc是有不同的方法的。ra寄存器存储的是函数的返回地址，当p0运行到上下文切换的最后一环，应该吧程序的运行权交还给p1，运行权还回来的时候代表设置的闹钟到期了。运行的事后续的逻辑。当希望程序向后执行一段执行sleep，sleep之后还有正常的逻辑，sleep指运行权交给别人，sleep之后把运行权还回来，那条指令就是switch to之后的那条指令，就是seitch to 的返回地址，调用函数的下一条指令就是返回地址，pc跳到了调用switch to的返回地址上，上下文再一次被回复，存到了ra之中，没有jmp ra也回不来，紧接着switch to

**创建存盘点**：

- 进程P1调用sleep，操作系统为其创建存盘点，保存当前寄存器状态和PC值（指向sleep后的下一条指令）。

**设置定时器（闹钟）**：

- 操作系统为P1设置一个定时器，表示sleep的时间长度。

**切换到其他进程**：

- 操作系统选择另一个就绪进程（例如P0），恢复其上下文并执行。

**定时器触发，恢复进程**：

- 当定时器到期，操作系统恢复P1的存盘点，将其PCB中的上下文加载到寄存器，P1继续从sleep后的指令执行。

在上下文切换中，switch_to是一个关键的函数或操作，用于实现进程切换。以下是其工作原理：

- 当P0运行到需要切换的时刻（例如调用sleep），操作系统调用switch_to函数。
- switch_to保存P0的上下文（包括PC和RA），并将P0的运行权交给P1。
- **返回地址（RA）**：
  - RA寄存器存储了调用switch_to后应返回的指令地址，即switch_to的下一条指令。
  - 当P1完成执行或定时器到期，操作系统恢复P0的上下文，PC跳转到RA存储的地址，P0继续执行。
- 如果没有正确设置RA或执行jmp ra（跳转到返回地址），进程无法正确恢复。

可以存下来运行的状态也可以回复这样的值，每一个进程都有一个pcb，也会加载他自身的PCB，上下文切换是通过写入寄存器与把寄存器的值进行上下切换来实现指令和数据的跳转，跳转到一个程序。switch to的一瞬间让p1执行，把p0存下来，jmp ra是从p1的存盘点存出来的。一个进程要放弃他的存盘权。retn回到调用的里面去。cin，cout都有一个switch to的功能。再运行是把switch to给我。

目前cpu有特权态和用户态，所有特权指令都写成了mips。每一个程序的暂停存档读档，读什么档。进程是对资源的占用，那个程序可以执行，应该运行哪些进程，需要对进程进行分类。如何完成对于进程的分类，状态模型。

进程分类，可以运行与不可运行。switchto能不能实现？用户自己实现设置？保证程序连续进行，不把进行权交给别人。x86的特权组织，cpu分为特权态和普通态。用户态/特权态（网络收数据，硬盘读数据，屏幕显示数据），调用代码除了带着应用态能还有收取数据的功能。为什么程序会被存档。

运行状态、就绪状态、结束状态。从就绪状态选一个来进行接管，每隔5ms发生只要不是取队头就会增加时间。运行状态、就绪状态转换到挂起状态。程序在内存中，原模原样写到内存之中。时间片越小越好？

**PO 和 CPO 在这段时间干什么？时间片大小问题**

1. **背景**
   - 场景里全是访存（load/store）指令，没有加减乘除等计算指令可以和访存混合执行。
   - 无论是乱序执行（Out-of-Order Execution）还是流水线（Pipeline），都无法缓解这个瓶颈，因为它们需要指令类型的多样性来隐藏延迟。
   - 所以 CPU 只能“干等”访存完成。
2. **PO（Program Order）**
   - 指令按程序顺序排队执行。
   - 在全是访存的情况下，PO 只能一条条等访存完成，几乎没事可干。
3. **CPO（Current Process Order / 当前进程的指令流）**
   - 当前进程的所有可执行指令都卡在访存上，没有其他运算可并行。
   - CPU 无法调度别的指令，只能等待数据从内存取回。
4. **上下文切换的意义**
   - 如果在这种等待中进行**上下文切换**，从 CPU 角度看是非常慢且浪费时间的，因为：
     - 切换本身需要保存/恢复寄存器、刷新缓存等，代价高。
     - 而且访存延迟并没有因为切换而缩短。
   - 因此 **时间片大小的选择** 要权衡：
     - 太小：频繁切换，浪费更多时间在切换上。
     - 太大：单个任务可能长时间占用 CPU，即使它一直在等内存。
   - **合理答案**：时间片应该根据 CPU–内存延迟、任务类型、调度策略等动态调整，而不是简单追求小或大。

**第二部分：CISC → RISC 后寄存器数量增加的问题及解决手段**

1. **背景变化**
   - CISC（复杂指令集计算机）时代，寄存器少（例如只有 7 个），大量工作交给内存。
   - RISC（精简指令集计算机）后，寄存器数量显著增加（RISC-V 有 32 个通用寄存器，ARM 也有更多）。
   - 这减少了内存访问次数，但也带来了寄存器管理的复杂性（尤其是函数调用时保存/恢复寄存器）。
2. **问题**
   - 寄存器越多，**上下文切换**或**函数调用**时需要保存/恢复的数据量越大，导致开销上升。
3. **解决手段**
   - **寄存器窗口（Register Windows）**：
     - 典型于 SPARC 架构，把寄存器分成重叠窗口，每个函数调用只用一部分寄存器，减少保存/恢复次数。
   - **延迟保存（Lazy Saving）**：
     - 上下文切换时只保存当前真正用到的寄存器，等到需要用时再保存剩余的。
   - **编译器寄存器分配优化**：
     - 编译器尽量减少跨函数调用时需要保存的寄存器数。
   - **硬件支持的快速上下文切换**：
     - 部分 CPU 有专门的硬件缓冲区或影子寄存器组，切换时直接替换指针而不是逐个保存。

1. **PO & CPO 在干啥？**
    在全是访存指令的情况下，PO 和 CPO 都只能等待数据返回，不能执行其他有用工作。上下文切换在此时对 CPU 几乎没有加速作用，反而因为切换成本大而浪费时间。时间片应合理设定，避免频繁切换造成更大开销。
2. **CISC → RISC 寄存器数量增加的问题怎么解决？**
    通过寄存器窗口、延迟保存、编译器优化和硬件加速切换等手段，减少保存/恢复寄存器的开销。

进程：只有一个cpu但想要程序齐头并进，要有一个存档于读档的操作，绝大部分在内存中，我们要存寄存器，就是存上下文，随时随地被存档与读档。数据结构和接口功能来支撑存档与读档。进程可以有存档和读档的功能，在什么时候存档与读档，划分成阻塞、就绪、运行![image-20250813160114915](C:\Users\gds\AppData\Roaming\Typora\typora-user-images\image-20250813160114915.png)![image-20250813160148294](C:\Users\gds\AppData\Roaming\Typora\typora-user-images\image-20250813160148294.png)

与cpu的对话需要六分钟，寄存器变多，从主存取一字节100ns，取100万需要25万ns，量大者优，一连串的寄存器/地址批量写内存，也可以批量的读内存。内存中有大量在分时复用，每个进程决定着存档与读档。一个进程停下来，还有若干个处于正在运行的动态进程。调度在传统的计算机是调度下一个进程。单核的世界中的问题不适用于多核cpu（部分）。什么时候做调度？从运行态中离开。有一段指令流填进cpu，什么东西可以打断？中断可以，指令流被操作系统劫持，去存档然后回来，这是抢占式的执行。抢占式非抢占式大量存在，抢占了cpo，上个进程的系统调用和下个进程的中断。先来先服务，先做运行时间短容易做完的。短任务有限的特性：平均周转时间短/剩余运行时间短。用已知预测未知。现代化的调度算法。时间片轮转有没有带来更多的计算资源，没有，也使得每一个程序变慢，每一个程序都在运行产生的假象。时间片大/小：cpu利用率pk用户满意度。程序运行一段cpo的计算就会去做一段时间的io，上下文切换，5ns可以完成90%以上的时间片，5ns的周期作时间片轮转？

1. CPU 与内存交互的基本特性

- **寄存器访问速度**：极快，可视为“CPU 内部”操作，延迟在皮秒级。
- **主存访问延迟**：取 1 字节约需 **100 ns**（数量级正确，但实际会因内存类型、总线宽度等不同而变化）。
- **大规模数据传输**：取 100 万字节（约 1 MB）理论耗时 ≈ `100 ns × 1,000,000 / 总线宽度`，实际中会用 **批量传输（burst transfer）** 缓解延迟。一连串寄存器/地址可以批量写入内存，也可批量读取，提高带宽利用率。
- **内存资源共享**：在多任务系统中，内存被大量进程分时复用，每个进程会在需要时保存（存档）和恢复（读档）自己的运行状态。

2. 多任务与调度

- **单核与多核差异**：传统调度模型假设单核 CPU，只能一次运行一个进程。多核 CPU 可以同时运行多个进程，因此部分单核调度策略在多核环境下效果不同。
- **调度触发时机**：
  1. 进程主动结束（正常退出）。
  2. 从运行态切换到等待态（例如等待 I/O）。
  3. 被中断（Interrupt）打断，触发抢占式调度。
- **抢占式调度**：操作系统通过中断劫持当前的指令流（CPO：当前进程的执行顺序），保存上下文（寄存器、程序计数器等），然后切换到另一个进程。广泛存在于现代系统，保障高优先级任务及时运行。
- **非抢占式调度**：进程运行直到主动放弃 CPU（如执行阻塞性 I/O）或结束。

3. 调度策略与特性

- **先来先服务（FCFS）**：简单易实现，但可能导致长作业阻塞短作业（Convoy effect）。
- **短作业优先（SJF）**：特性：平均周转时间短。现实问题：无法完全预知任务长度 → 用“已知预测未知”（历史运行时间预测剩余运行时间）。
- **剩余时间最短优先（SRTF）**：动态版本的短作业优先，适合交互型任务。
- **现代调度算法**：综合优先级、响应时间、吞吐量等多因素（如 Linux CFS，Windows MLFQ）。

4. 时间片轮转（Round Robin）

- **作用**：分配固定 CPU 时间片，周期性切换任务。让每个任务都获得运行机会 → “假象”是所有程序同时运行。
- **缺点**：并不会带来更多计算资源，切换频繁反而让每个程序变慢（上下文切换开销）。
- **时间片大小权衡**：**大时间片**：切换少，CPU 利用率高，但交互延迟高，用户体验差。**小时间片**：响应好，用户满意度高，但上下文切换频繁，CPU 时间浪费多。**合理选择**：取 CPU 利用率与用户响应的平衡点。
- **时间片与 I/O**：程序运行一段时间的 CPU 计算后，往往会进入 I/O 等待阶段，此时发生上下文切换。
- **不准确原文修正**：“5 ns 可以完成 90% 的时间片”这一说法不现实，现代时间片一般在 **1–10 ms** 量级，5 ns 甚至比一次寄存器访问还短，无法作为时间片周期。

5. 关键结论

1. CPU 与内存速度差距巨大，批量传输可部分缓解延迟。
2. 上下文切换是调度的核心，但有开销，频繁切换会降低整体性能。
3. 时间片轮转是公平调度的手段，但需平衡响应速度与 CPU 利用率。
4. 多核 CPU 的调度需要考虑核间负载均衡，与单核策略不同。
5. 对任务长度的合理预测是优化调度的重要手段。

时间片沿用性质5ns，cache line的字节，cache的局部性为了保证性能维持了之前的规则，人不会有耐心调优所有的程序。每隔5ns产生一个时钟中断先看队列中优先级最高的。优先级越高希望越快地进行，io多的进程cpu利用率低，为什么给他更高的优先级，是为了满足更好的用户体验；大量等待io的进程任务并不多，为了更好的用户体验和io，cpo的利用率。更高的优先级有更高的系统资源。基于时间片/时间片结合优先级等等的调度策略，连续求解器。有策略有参数，找一个好的调度策略。cpu使用率，吞吐量，周转时间、等待时间，响应时间，高吞吐与低延迟两大目标。高吞吐通常需要高延迟，等待吞吐量的增加就会产生延迟。低延迟设置一个专门的通道。上下文调度在是哪偏重产生了很多负担。多核处理器一片内存若干个处理器，借助总线访问外部的内存。若干个处理器打包成盒和总线连接一起。cpu之间的负载均衡，task stealing。根据每个任务对cpu的渴求度来确定cpu的负载，有多少处于活跃状态，谁处于阻塞状态，谁处于运行状态。我们如何以微秒为单位计量每个程序对我的cpo任务的负载的贡献和如何高效统计处于阻塞和运行状态的程序。华为前端后端一起变异，SDK，app打包在一起，好处和坏处。坏处每个app都有专门的版本虽然一统江湖；但是windows开放式的可以蓬勃发展，华为搞了新的生态

1. 时间片与调度触发

- **时间片延续性**笔记中提到“5ns 时间片”不现实——现代 CPU 的时间片通常在 **1–10ms** 量级，5ns 甚至比一次 L1 缓存访问还短。5ns 更接近**时钟周期级中断或计时器分辨率**的概念，不是调度用的实际时间片长度。
- **调度触发机制**每次时钟中断（Timer Interrupt）到来时，调度器检查就绪队列，选择优先级最高的任务运行。优先级越高的任务会更快得到 CPU 资源。

2. 优先级与 I/O 密集型任务

- **I/O 密集型任务特点**：CPU 利用率低，大部分时间在等待 I/O。通常给予更高优先级，以便更快响应用户操作（提高交互体验）。I/O 等待多的进程往往任务量少，调度器可以频繁唤醒它们，保持流畅体验。
- **高优先级效果**：更多系统资源（CPU 时间、I/O 通道）倾向于高优先级进程。有助于降低交互延迟，但会影响低优先级任务的吞吐量。

3. 调度策略

- **基于时间片**（Round Robin）：公平分配 CPU 时间，适合无明显优先级差别的任务。
- **时间片结合优先级**（Multilevel Feedback Queue, MLFQ）：根据任务行为调整优先级。
- **连续求解器/特定算法**：针对计算密集型或长任务，优化吞吐量。
- **策略调优目标**：
  - CPU 使用率（CPU Utilization）
  - 吞吐量（Throughput）
  - 平均周转时间（Turnaround Time）
  - 等待时间（Waiting Time）
  - 响应时间（Response Time）
- **目标冲突**：高吞吐量通常会增加延迟（批处理倾向）。低延迟优化会降低整体吞吐量。一种折衷方法是为低延迟任务开辟专用通道（类似实时调度队列）。

4. 上下文切换的代价

上下文切换会保存和恢复寄存器、程序计数器、缓存等，增加系统负担。过于频繁的切换会显著降低 CPU 有效利用率。调度策略在“公平性”和“上下文切换开销”之间需要平衡。

5. 多核 CPU 与负载均衡

- **硬件结构**：多核处理器共享一片主内存，通过总线访问外部存储器。多个 CPU 核打包在一个芯片或封装内，通过总线互连。
- **负载均衡策略**：**Task Stealing**：空闲的 CPU 核从繁忙核的任务队列中“偷取”任务执行。根据任务的 CPU 渴求度（CPU-bound 程度）调整分配策略。统计各核上任务的活跃状态（Running）、阻塞状态（Blocked）等，以微秒级精度评估负载。高效统计方法依赖内核调度器的运行队列信息和性能计数器。

6. 华为与 Windows 生态差异（软件打包模式）

- **华为模式**：前端、后端、SDK、App 打包为一体，形成封闭生态。优点：生态统一、版本兼容性好、优化可控。缺点：每个 App 都需专用版本，开发灵活性低，第三方创新空间受限。
- **Windows 模式**：开放式生态，前后端解耦，可在多种硬件和软件环境运行。优点：兼容性广、生态繁荣。缺点：碎片化、优化难度大，需要开发者自行适配。

存储片不是串联使用而是并联使用，内存插头八条或十六条，起着内存读写的作用。越大的计算机内存条数越多，现在遇到的问题是内存不够用，cpu很多。不能能做很大的cache，cache大检索速度不会太快，要了memary是不是够用。什么是内存地址，把内存的数据存到寄存器，做运算然后得到结果，操作系统把写好的程序加载到内存之中。dos放在低十六位的内存之中。内存可以装许多曾经写过的程序，把内存切成若干片段，把程序同时调进去。每一个进程有一半的时间做io，一半时间做计算，提供并行，随着投入的进程数增多也可以吧cpu利用率接近100%。扩容后需要对内存做编排。程序开发之中通过编译和连接制定程序的地址，在运行的时候会重新修改地址。函数会变成跳转指令跳转函数，汇编语句给函数编地址。连接把系统库和代码堆到一起。操作系统和编译者找到175改成1175。连接器和加载器，扫描程序代码找到需要修改地方进行修改很麻烦，软件不够硬件来凑，硬件中的基址寻址，自动地加载到基址上。看到硬件有了功能来使用功能，加载的时候不再需要软件扫描。175-1175的访问，把内存区域划分为长度限定好的段，段基址寄存器和长度寄存器设置好。操作系统按段切内存然后分配。段寄存器和长度寄存器，内存的分配。进程退出会留出一个洞，越来越多失去内存区域，保存空闲内存有多少，在哪里，用数组即可，用数组记录内存分配在哪里。双链表避免遍历两边。分配内存按什么原则分配呢，最先适配，最佳适配，最差适配，下次适配。堆：通过logn时间复杂度的调整得到最大者。

1. 内存硬件结构

- **并联结构**存储条（内存条）不是串联使用，而是**并联**在内存总线上工作。主板上的内存插槽通常为 **8 条** 或 **16 条**（大规模服务器可能更多），每条内存同时参与读写。内存容量越大，内存条数量通常越多。
- **问题现状**现代系统中 **CPU 核数很多**，但**内存容量不足**成为瓶颈。Cache（高速缓存）不能无限增大：容量大了检索速度会降低，且成本高。

2. 内存与地址概念

- **内存地址**：表示内存中每个字节（或字）的位置。
- **CPU 与内存交互过程**：
  1. 从内存中取数据到寄存器。
  2. 在寄存器中执行计算。
  3. 将结果写回内存。
- **程序加载**：操作系统将编译好的程序加载到内存中。早期 DOS 系统的内核常驻在低 16 位地址空间（低端内存）。
- **多程序装载**：内存可以同时装载多个程序，将内存划分为多个片段（分区）。不同进程可并行执行：通常一个进程 **约一半时间在计算**、**一半时间等待 I/O**，因此多进程能使 CPU 利用率接近 100%。

3. 内存扩容与地址管理

- 扩容后需要重新编排内存分配，保证空间合理利用。
- **编译与链接**：
  1. **编译**：将源代码转换为目标代码，给函数和变量分配**逻辑地址**。
  2. **链接**：将目标代码与系统库合并，调整地址（可能变为 1175 而不是原来的 175）。
  3. **加载**：将可执行文件装入内存，确定实际物理地址。
- **早期方法**：连接器和加载器需扫描整个程序代码，找到所有需要调整的地址，非常麻烦。
- **硬件基址寻址（Base Register Addressing）**：利用基址寄存器（Base Register）自动在运行时为逻辑地址加上基址偏移。这样加载时无需软件逐一扫描调整地址。示例：逻辑地址 175，在基址 1000 时，实际访问物理地址 1175。

4. 段式内存管理

- **段划分**：内存划分为多个段（Segment），每段有固定长度。段基址寄存器（Segment Base Register）存放段起始物理地址。段长度寄存器（Segment Limit Register）存放该段长度。
- **操作系统分配内存**：按段为进程分配所需空间。当进程退出时释放段空间，可能会留下**内存碎片**（空洞）。

5. 空闲内存管理

- **记录方式**：用数组记录空闲内存块的位置和大小。使用双链表可避免双向遍历的效率问题（可快速合并相邻空闲块）。
- **分配策略**：
  1. **首次适配（First Fit）**：从头开始找，找到第一个足够大的空闲块就分配。
  2. **最佳适配（Best Fit）**：找最接近所需大小的空闲块，减少碎片。
  3. **最差适配（Worst Fit）**：分配最大的空闲块，保留较大的剩余块。
  4. **下次适配（Next Fit）**：从上次分配结束的位置继续寻找。
- **堆（Heap）管理**：可用堆结构管理空闲块（按大小排序）。堆调整复杂度 O(log n)，可快速找到最大或最小的可用块。

6. 关键点总结

1. 内存条并联在总线上，容量大依赖插槽数量和单条容量。
2. Cache 不可无限增大，否则会降低访问速度。
3. 现代多进程利用 I/O 等待隐藏 CPU 空闲，提升利用率。
4. 基址寄存器等硬件机制能极大简化地址重定位。
5. 段式管理与空闲块管理策略直接影响内存利用效率。
6. 碎片管理是长期运行系统的内存优化重点。

多核轮转，o1优化器，基于哈希选择下一个进程，内存管理两个阶段，程序用不完内存，随着高级语言的出现，软件开发的成熟，把内存切成块，一块一块拿给应用程序去用，基于硬件支持的分块的内存加载，空闲的单链表需要o（n），内存的空闲态组成一个堆，然而连续内存是系统的宝贵资源。伙伴系统（linux），并不把切下来的16k留下来，找到大于他的最小值进行分配，进程退出后会被操作系统回收。找到跟他大小匹配的块速度很快，并不产生额外的碎片，进程退出内存回收和合并的机制不错。在空洞管理和内存合并仍然得不到想要的内存数量？每一个进程来了分一块内存，其是否退出，我们可以把内存放在任意位置上只要他们不重叠。运行进程占用大量内存空间满足不了需要，额能否驱逐一个数据？可以吧现在内存当中一部分挪到内存上去，挪到磁盘上去挂起，想要再运行就是挂起后运行。预先知道程序走什么分支，然后加载到程序之中，最大的困难不在于走什么分支overlay，是一个矛盾，游戏中的过场动画就是作一个分支，运行到这个分支，释放上一个。

1. 多核调度与 O(1) 优化器

- **多核轮转调度**多核 CPU 上的调度器会在不同核心间轮转运行进程，以均衡负载。需要避免频繁跨核迁移进程，因为这会导致缓存失效（Cache Miss）和性能下降。
- **O(1) 调度优化器**Linux 曾使用的 O(1) 调度器可在常数时间内（O(1)）选出下一个要运行的进程。实现方式：基于哈希表（或多级就绪队列）快速定位优先级最高的可运行任务。目标是调度决策耗时与就绪队列长度无关。

2. 内存管理的两个阶段

1. **分配阶段**
   - 程序申请内存，操作系统将可用物理内存分配给它。
   - 高级语言出现后，软件开发趋于成熟，操作系统将内存**切成块**（固定大小或可变大小），按需分配给应用程序。
   - 借助硬件支持（如分页、分段），内存可以按块加载到不同物理位置。
2. **回收阶段**
   - 程序结束或释放内存时，操作系统回收空间，并尝试合并相邻空闲块以减少碎片。

3. 空闲内存管理策略

- **单链表空闲块管理**用单链表存储空闲块，查找合适块的时间复杂度为 O(n)，效率较低。
- **堆（Heap）管理**用堆结构（优先队列）存储空闲块，可以在 O(log n) 时间内找到最大或最小的可用块。
- **连续内存的重要性**连续物理内存是系统的宝贵资源，尤其对 DMA、显卡、驱动等硬件访问至关重要。

4. Linux 伙伴系统（Buddy System）

- **分配原理**：
  1. 内存以 2 的幂次大小为单位进行管理（如 4K、8K、16K、32K…）。
  2. 当申请大小不是 2 的幂时，向上取最近的 2 的幂。
  3. 找到大于等于所需大小的最小可用块进行分配。
- **回收与合并**：当进程退出时，操作系统回收其内存块。若相邻内存块大小相等且都空闲，则合并为更大的块。
- **优点**：分配速度快（常数时间或接近常数时间）。合并机制可有效减少外部碎片。
- **不足**：当所需内存量大于可用的连续块大小时，即使总空闲内存充足，也可能分配失败（外部碎片问题仍存在）。

5. 内存不够时的处理

- **任意位置分配**在虚拟内存系统下，只要物理页不重叠，就可将不同进程的内存块分配在任意位置。
- **换出（Swap Out）机制**当运行进程占用大量内存且系统无法满足需求时，可以将部分数据从内存移到磁盘（Swap Space）。被换出的进程进入挂起状态（Suspended），需要时再换入（Swap In）。
- **覆盖（Overlay）技术**（早期方法）：程序运行时只保留必要部分，按逻辑模块分段。当运行到新模块时，释放上一个模块的内存，将新模块加载到原位置。典型应用：游戏中的过场动画会释放不必要的游戏逻辑模块，仅保留动画所需数据，播放结束后再加载游戏逻辑。

6. 关键总结

1. 多核调度需在公平性、负载均衡和缓存命中率之间权衡。
2. O(1) 调度器通过常数时间选择进程，大幅提升调度效率。
3. 内存管理分为分配和回收两个阶段，硬件分页/分段机制是基础。
4. 伙伴系统能快速分配和合并内存块，但仍可能遇到外部碎片问题。
5. 内存不足时可使用虚拟内存（Swap）或覆盖（Overlay）技术释放空间。



